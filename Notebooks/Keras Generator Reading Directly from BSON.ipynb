{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75d61c38-954c-4bd1-a127-5d17e1812402",
    "_uuid": "2ae1f395d8768512da0739dded661e329dbfa14e"
   },
   "source": [
    "This notebook contains a generator class for Keras called `BSONIterator` that can read directly from the BSON data. You can use it in combination with `ImageDataGenerator` for doing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_names.csv\n",
      "test.bson\n",
      "train.bson\n",
      "train_example.bson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import *\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "3601ddc2-5dca-463c-be54-a297e019469a",
    "_uuid": "41fb122f53b29ff6c7cdba4f08001fa8204fab34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.8', '1.3.0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "dfec6cb3-3b14-44cc-920c-c4bba4f79589",
    "_uuid": "1d92f3f86af7906e204eec1d536bd29878fed02d"
   },
   "outputs": [],
   "source": [
    "data_dir = \"input/\"\n",
    "\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "num_train_products = 7069896\n",
    "\n",
    "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "# num_train_products = 82\n",
    "\n",
    "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "num_test_products = 1768182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c24b66f-0f55-4007-86d9-aae6ec1c16bc",
    "_uuid": "0c1457925b72937cc9b8d431142f06098cbfe06c"
   },
   "source": [
    "# Part 1: Create lookup tables\n",
    "\n",
    "The generator uses several lookup tables that describe the layout of the BSON file, which products and images are part of the training/validation sets, and so on.\n",
    "\n",
    "You only need to generate these tables once, as they get saved to CSV files. If you already have these CSV files, skip to part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "593c6f49-83eb-4491-bcd1-0131845e395c",
    "_uuid": "7ea59756f0ab3eb271e2b5d6495e6a158311de35"
   },
   "source": [
    "## Lookup table for categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "92491e45-56da-4d64-a887-6cf7a8c8cd30",
    "_uuid": "05ccbed26b3518d90ddcc9c26668f6008b89cb0f"
   },
   "source": [
    "Create dictionaries for quick lookup of `category_id` to `category_idx` mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "7aad702e-68b9-4c94-a6e7-910283629011",
    "_uuid": "1c40f20530ad22246d6941845c89b210b4a85368"
   },
   "outputs": [],
   "source": [
    "def make_category_tables():\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4518fba-7f26-45c1-ae3f-daf72ffbbee9",
    "_uuid": "51f82526d1ce6b7ab0b4d5b370f0f2f9601dbc66"
   },
   "source": [
    "## Read the BSON files\n",
    "\n",
    "We store the offsets and lengths of all items, allowing us random access to the items later.\n",
    "\n",
    "Inspired by code from: https://www.kaggle.com/vfdev5/random-item-access\n",
    "\n",
    "Note: this takes a few minutes to execute, but we only have to do it once (we'll save the table to a CSV file afterwards)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1da50467-d11d-417e-9367-bd8574dfe61a",
    "_uuid": "55331a57195739250c5b530160cf32a57b9a2464"
   },
   "source": [
    "First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "19c24f98-551d-4b95-b8f7-8497ab09eb56",
    "_uuid": "0c0dadb16f6b094748e967e9c682bb18b3b5c336"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "categories_df = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "cat2idx, idx2cat = make_category_tables()\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17cb7bb4-4941-4d0d-8fa5-2dd60b7014ce",
    "_uuid": "edbb272356d65e3ec9b540bd4597464ae4afa3c5"
   },
   "source": [
    "The Keras generator is implemented by the `BSONIterator` class. It creates batches of images (and their one-hot encoded labels) directly from the BSON file. It can be used with multiple workers.\n",
    "\n",
    "**Note:** For fastest results, put the train.bson and test.bson files on a fast drive (SSD).\n",
    "\n",
    "See also the code in: https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "78d8b565-336e-4836-b613-768bb6581499",
    "_uuid": "c43d82c645b098b2dd8fc0962bd392bdfc43057d"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "class BSONIterator(Iterator):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, num_class,\n",
    "                 image_data_generator, lock, target_size=(180, 180), \n",
    "                 with_labels=True, batch_size=32, shuffle=False, seed=None):\n",
    "\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.with_labels = with_labels\n",
    "        self.samples = len(images_df)\n",
    "        self.num_class = num_class\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.image_shape = self.target_size + (3,)\n",
    "\n",
    "        print(\"Found %d images belonging to %d classes.\" % (self.samples, self.num_class))\n",
    "\n",
    "        super(BSONIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n",
    "        self.lock = lock\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n",
    "        if self.with_labels:\n",
    "            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            # Protect file and dataframe access with a lock.\n",
    "            with self.lock:\n",
    "                image_row = self.images_df.iloc[j]\n",
    "                product_id = image_row[\"product_id\"]\n",
    "                offset_row = self.offsets_df.loc[product_id]\n",
    "\n",
    "                # Read this product's data from the BSON file.\n",
    "                self.file.seek(offset_row[\"offset\"])\n",
    "                item_data = self.file.read(offset_row[\"length\"])\n",
    "\n",
    "            # Grab the image from the product.\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            img_idx = image_row[\"img_idx\"]\n",
    "            bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
    "\n",
    "            # Load the image.\n",
    "            img = load_img(io.BytesIO(bson_img), target_size=self.target_size)\n",
    "\n",
    "            # Preprocess the image.\n",
    "            x = img_to_array(img)\n",
    "            x = self.image_data_generator.random_transform(x)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "\n",
    "            # Add the image and the label to the batch (one-hot encoded).\n",
    "            batch_x[i] = x\n",
    "            if self.with_labels:\n",
    "                batch_y[i, image_row[\"category_idx\"]] = 1\n",
    "\n",
    "        if self.with_labels:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "#         return self._get_batches_of_transformed_samples(index_array)\n",
    "        return self._get_batches_of_transformed_samples(index_array[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "86525843-13cc-413e-b372-085e4864a45a",
    "_uuid": "a1de21a39914a95128adb7675b5fa17a5284f338"
   },
   "outputs": [],
   "source": [
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c1f8649-6383-4ccf-9b72-0a33d4011019",
    "_uuid": "65d447e854e1bc67a3046d8318240f1b71814d4b"
   },
   "source": [
    "Because the training and validation generators read from the same BSON file, they need to use the same lock to protect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "13fc319e-fc07-4ba8-a293-807f0a588cae",
    "_uuid": "4b3c7259068815be68ae576136ad67b0c7bc89a6"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2742b451-159b-4353-a7eb-96885fdf8919",
    "_uuid": "a4a76294778c99600228091e797507026d8ba4c3"
   },
   "source": [
    "Create a generator for training and a generator for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "d9381773-ad58-4656-b225-306e68a603f7",
    "_uuid": "ffc317a85c6849dca92c8e5322eecff66269cca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9901166 images belonging to 5270 classes.\n",
      "Found 2470127 images belonging to 5270 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5270\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "batch_size = 128\n",
    "\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         num_classes, train_datagen, lock,\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
    "                       num_classes, val_datagen, lock,\n",
    "                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c5871a3-6d4a-4260-b8d4-462454ad8983",
    "_uuid": "c3cb7cadf70e26f22f9cd35f8f375b4e9483325a"
   },
   "source": [
    "How fast is the generator? Create a single batch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2250dba6-6ab0-4417-854e-6a3eb924fc33",
    "_uuid": "3daa4847924e17f4bab9a58470460667dc517075"
   },
   "source": [
    "# Part 3: Training\n",
    "\n",
    "Create a very simple Keras model and train it, to test that the generators work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "eaa3b3ba-7502-445f-91da-26d29af2bee8",
    "_uuid": "126271374bf7cfcf0871b8b78441e1f1dfa05cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 180, 180, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5270)              342550    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               674688    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5270)              679830    \n",
      "=================================================================\n",
      "Total params: 1,720,652\n",
      "Trainable params: 1,720,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, padding=\"same\", activation=\"relu\", input_shape=(180, 180, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b8d0061-a07c-4a78-b53c-6ca1a2cf9799",
    "_kg_hide-output": false,
    "_uuid": "ce48a33358e9824f2c19e2c69878be9762915b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 9390/77352 [==>...........................] - ETA: 18184s - loss: 6.9106 - acc: 0.0066"
     ]
    }
   ],
   "source": [
    "# To train the model:\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch = num_train_images // batch_size,\n",
    "                    epochs = 3,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = num_val_images // batch_size,\n",
    "                    workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2822e2c-6b4e-4b8b-b346-86e4b5feeb42",
    "_uuid": "3303ec963fa2aeef322fd9d864b296ba1bbb04b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To evaluate on the validation set:\n",
    "#model.evaluate_generator(val_gen, steps=num_val_images // batch_size, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2116a8c3-ec60-4878-93af-94c185c08cb3",
    "_uuid": "ee05e14fd2e9354008f23941f97ee3ff7ff73aaf"
   },
   "source": [
    "# Part 4: Test set predictions\n",
    "\n",
    "Note: The previous version of this kernel used `BSONIterator` to load the test set images in batches. However, storing the prediction results takes up a huge amount of memory. \n",
    "\n",
    "I suggest using a different kind of generator instead, something like the following:\n",
    "\n",
    "```\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "submission_df = pd.read_csv(data_dir + \"sample_submission.csv\")\n",
    "submission_df.head()\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "data = bson.decode_file_iter(open(test_bson_path, \"rb\"))\n",
    "\n",
    "with tqdm(total=num_test_products) as pbar:\n",
    "    for c, d in enumerate(data):\n",
    "        product_id = d[\"_id\"]\n",
    "        num_imgs = len(d[\"imgs\"])\n",
    "\n",
    "        batch_x = np.zeros((num_imgs, 180, 180, 3), dtype=K.floatx())\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            bson_img = d[\"imgs\"][i][\"picture\"]\n",
    "\n",
    "            # Load and preprocess the image.\n",
    "            img = load_img(io.BytesIO(bson_img), target_size=(180, 180))\n",
    "            x = img_to_array(img)\n",
    "            x = test_datagen.random_transform(x)\n",
    "            x = test_datagen.standardize(x)\n",
    "\n",
    "            # Add the image to the batch.\n",
    "            batch_x[i] = x\n",
    "\n",
    "        prediction = model.predict(batch_x, batch_size=num_imgs)\n",
    "        avg_pred = prediction.mean(axis=0)\n",
    "        cat_idx = np.argmax(avg_pred)\n",
    "        \n",
    "        submission_df.iloc[c][\"category_id\"] = idx2cat[cat_idx]        \n",
    "        pbar.update()\n",
    "        \n",
    "submission_df.to_csv(\"my_submission.csv.gz\", compression=\"gzip\", index=False)        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cbfc7694-29b3-4197-b2dd-daca30ed7468",
    "_uuid": "63f279cfa4548b449061ab932e15005d1ee59e26",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
